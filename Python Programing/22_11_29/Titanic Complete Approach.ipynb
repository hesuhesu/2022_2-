{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d803201e-d81c-4d7c-bdec-82e34394862c",
   "metadata": {},
   "source": [
    "## Section 1 - Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31849d-807a-466f-a0fc-e86184f7cc8c",
   "metadata": {},
   "source": [
    "The first step is to import needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65856f23-55c8-44e7-8d16-cb5ec4e8ed82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataError' from 'pandas.core.base' (C:\\Users\\sky\\.conda\\envs\\python\\lib\\site-packages\\pandas\\core\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycle \u001b[38;5;66;03m# used for cycling colors at plotly graphs\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m# plotting library\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m \u001b[38;5;66;03m# library for automatic EDA\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# installing and importing autoviz, another library for automatic data visualization\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautoviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAutoViz_Class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoViz_Class\n",
      "File \u001b[1;32m~\\.conda\\envs\\python\\lib\\site-packages\\pandas_profiling\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontroller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[1;32m~\\.conda\\envs\\python\\lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_report\u001b[39m(df: DataFrame, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ProfileReport:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124;03m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python\\lib\\site-packages\\pandas_profiling\\profile_report.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, Settings\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectations_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExpectationsReport\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdescribe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m describe \u001b[38;5;28;01mas\u001b[39;00m describe_df\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageType\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sample\n",
      "File \u001b[1;32m~\\.conda\\envs\\python\\lib\\site-packages\\pandas_profiling\\model\\describe.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisionsTypeset\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorrelations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_correlation\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mduplicates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_duplicates\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sample, get_sample\n",
      "File \u001b[1;32m~\\.conda\\envs\\python\\lib\\site-packages\\pandas_profiling\\model\\correlations.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataError\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DataError' from 'pandas.core.base' (C:\\Users\\sky\\.conda\\envs\\python\\lib\\site-packages\\pandas\\core\\base.py)"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import string # library used to deal with text data\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library\n",
    "pd.set_option('display.max_columns', 100) # Setting pandas to display a N number of columns\n",
    "pd.set_option('display.max_rows', 10) # Setting pandas to display a N number rows\n",
    "pd.set_option('display.width', 100) # Setting pandas dataframe display width to N\n",
    "\n",
    "from scipy import stats # statistical library\n",
    "from statsmodels.stats.weightstats import ztest # statistical library for hypothesis testing\n",
    "import plotly.graph_objs as go # interactive plotting library\n",
    "import plotly.express as px # interactive plotting library\n",
    "from itertools import cycle # used for cycling colors at plotly graphs\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import pandas_profiling # library for automatic EDA\n",
    "\n",
    "# installing and importing autoviz, another library for automatic data visualization\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "from IPython.display import display # display from IPython.display\n",
    "from itertools import cycle # function used for cycling over values\n",
    "\n",
    "# installing ppscore, library used to check non-linear relationships between our variables\n",
    "import ppscore as pps # importing ppscore\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4b853-d2d2-452f-ac5f-0e49e847036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"data/input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "print(\"\")\n",
    "for dirname, _, filenames in os.walk('data/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b6afa-c122-485f-a388-77c3c94c0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check : os.walk\n",
    "for files in os.walk('data'):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602c6ad-5bf2-413b-8eeb-378ba5bf57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data and displaying some rows\n",
    "df = pd.read_csv(\"data/input/train.csv\")\n",
    "display(df.head()) # df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a9b72-d140-49d9-8e9b-fc48265f6032",
   "metadata": {},
   "source": [
    "##### pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331416a-9467-4de4-8490-6379186a6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pandas profiling library is really useful on helping us \n",
    "# understand the data we're working on.\n",
    "# It saves us some precious time on the EDA process.\n",
    "report = pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b9889-c573-4da7-a570-7692aa1203d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now visualize the report generated by pandas_profiling.\n",
    "# display(report)\n",
    "# Also, there is an option to generate an .HTML file containing all the information generated by the report.\n",
    "report.to_file(output_file='data/Profiling_Report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fa627-99a2-4864-8796-3a2bcf373947",
   "metadata": {},
   "source": [
    "##### AutoViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadf9db-0376-4b51-b563-8c352d064486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another great library for automatic EDA is AutoViz.\n",
    "# With this library, several plots are generated with only 1 line of code.\n",
    "# When combined with pandas_profiling, we obtain lots of information in a\n",
    "# matter of seconds, using less than 5 lines of code.\n",
    "AV = AutoViz_Class()\n",
    "\n",
    "# Let's now visualize the plots generated by AutoViz.\n",
    "report_2 = AV.AutoViz(filename=\"data/input/train.csv\", verbose=2, save_plot_dir=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e4907-3bbc-4ebd-80fb-796e9e57f0ba",
   "metadata": {},
   "source": [
    "### More Exploration\n",
    "First, let's take a look at the differences between the ages of both groups, using a Violin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fae593-9afb-44ba-bfb4-210908a722da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating different datasets for survivors and non-survivors\n",
    "df_survivors = df[df['Survived'] == 1]\n",
    "df_nonsurvivors = df[df['Survived'] == 0]\n",
    "\n",
    "display(df_survivors.head())\n",
    "display(df_nonsurvivors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3a4ba-a4f2-4e9b-bb51-ecbd1742109d",
   "metadata": {},
   "source": [
    "##### plotly.graph_objs -> go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70b1aa-bca0-4e12-b3c0-77261cd3d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the data inside the Violin Objects \n",
    "# (import plotly.graph_objs as go # interactive plotting library)\n",
    "violin_survivors = go.Violin(\n",
    "    y=df_survivors['Age'],\n",
    "    x=df_survivors['Survived'],\n",
    "    name='Survivors',\n",
    "    marker_color='forestgreen',\n",
    "    box_visible=True)\n",
    "\n",
    "violin_nonsurvivors = go.Violin(\n",
    "    y=df_nonsurvivors['Age'],\n",
    "    x=df_nonsurvivors['Survived'],\n",
    "    name='Non-Survivors',\n",
    "    marker_color='darkred',\n",
    "    box_visible=True)\n",
    "\n",
    "data = [violin_nonsurvivors, violin_survivors]\n",
    "\n",
    "# Plot's Layout (background color, title, etc.)\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    title='\"Age\" of survivors vs Ages of non-survivors',\n",
    "    xaxis=dict(\n",
    "        title='Survived or not'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Age'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704dce4-5e46-44a1-a422-2b61c97b161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First distribution for the hypothesis test: Ages of survivors\n",
    "dist_a = df_survivors['Age'].dropna()\n",
    "\n",
    "# Second distribution for the hypothesis test: Ages of non-survivors\n",
    "dist_b = df_nonsurvivors['Age'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41730793-0893-47dd-991b-1b07fbd53547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-test: Checking if the distribution means \n",
    "# (ages of survivors vs ages of non-survivors) are statistically different\n",
    "t_stat, p_value = ztest(dist_a, dist_b)\n",
    "print(\"----- Z Test Results -----\")\n",
    "print(\"Test stat. = \" + str(t_stat))\n",
    "print(\"P value = \" + str(p_value)) # P-value is less than 0.05\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# T-test: Checking if the distribution means \n",
    "# (ages of survivors vs ages of non-survivors) are statistically different\n",
    "t_stat_2, p_value_2 = stats.ttest_ind(dist_a, dist_b)\n",
    "print(\"----- T Test Results -----\")\n",
    "print(\"Test stat. = \" + str(t_stat_2))\n",
    "print(\"P value = \" + str(p_value_2)) # P-value is less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc647292-1cff-4f01-a8b3-f15fd463471f",
   "metadata": {},
   "source": [
    "#### \"Gender\" percentage from Survivors vs non-Survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d389e1-d193-4052-99cd-76a8516105f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check \n",
    "df_survivors['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ed658-0878-49e9-bec6-893f10cac13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the count of each Gender value inside the Survivors\n",
    "df_survivors_Gender = df_survivors['Gender'].value_counts()\n",
    "df_survivors_Gender = pd.DataFrame({'Gender':df_survivors_Gender.index, 'count':df_survivors_Gender.values})\n",
    "\n",
    "# Taking the count of each Gender value inside the Survivors\n",
    "df_nonsurvivors_Gender = df_nonsurvivors['Gender'].value_counts()\n",
    "df_nonsurvivors_Gender = pd.DataFrame({'Gender':df_nonsurvivors_Gender.index, 'count':df_nonsurvivors_Gender.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121435ee-8877-42e8-91d3-56d68e1931f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_survivors_Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972c65c-5c78-4a0b-8d2e-7efe5cde41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plotting objects\n",
    "pie_survivors_Gender = go.Pie(  \n",
    "   labels = df_survivors_Gender['Gender'],\n",
    "   values = df_survivors_Gender['count'],\n",
    "   domain=dict(x=[0, 0.5]),\n",
    "   name='Survivors',\n",
    "   hole = 0.5,\n",
    "   marker = dict(colors=['violet', 'cornflowerblue'], line=dict(color='#000000', width=2))\n",
    ")\n",
    "\n",
    "pie_nonsurvivors_Gender = go.Pie(  \n",
    "   labels = df_nonsurvivors_Gender['Gender'],\n",
    "   values = df_nonsurvivors_Gender['count'],\n",
    "   domain=dict(x=[0.5, 1.0]), \n",
    "   name='non-Survivors',\n",
    "   hole = 0.5,\n",
    "   marker = dict(colors=['cornflowerblue', 'violet'], line=dict(color='#000000', width=2))\n",
    ")\n",
    "\n",
    "data = [pie_survivors_Gender, pie_nonsurvivors_Gender]\n",
    "\n",
    "# Plot's Layout (background color, title, annotations, etc.)\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    title='\"Gender\" percentage from Survivors vs non-Survivors',\n",
    "    annotations=[dict(text='Survivors', x=0.18, y=0.5, font_size=15, showarrow=False),\n",
    "                 dict(text='Non-Survivors', x=0.85, y=0.5, font_size=15, showarrow=False)]\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21567982-5d96-46ac-be6d-7a4c863f7213",
   "metadata": {},
   "source": [
    "#### \"Pclass\" percentage from Survivors vs non-Survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eef228-b735-4f52-a913-6e949644b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the count of each Pclass value inside the Survivors\n",
    "df_survivors_pclass = df_survivors['Pclass'].value_counts()\n",
    "df_survivors_pclass = pd.DataFrame({'Pclass':df_survivors_pclass.index, \n",
    "                                    'count':df_survivors_pclass.values})\n",
    "\n",
    "# Taking the count of each Pclass value inside the Survivors\n",
    "df_nonsurvivors_pclass = df_nonsurvivors['Pclass'].value_counts()\n",
    "df_nonsurvivors_pclass = pd.DataFrame({'Pclass':df_nonsurvivors_pclass.index, \n",
    "                                       'count':df_nonsurvivors_pclass.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517c1cc-f783-4f7d-bf77-bfc2ed55abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plotting objects\n",
    "pie_survivors_pclass = go.Pie(  \n",
    "   labels = df_survivors_pclass['Pclass'],\n",
    "   values = df_survivors_pclass['count'],\n",
    "   domain=dict(x=[0, 0.5]),\n",
    "   name='Survivors',\n",
    "   hole = 0.5,\n",
    "   marker = dict(colors=['#636EFA', '#EF553B', '#00CC96'], \n",
    "                 line=dict(color='#000000', width=2))\n",
    ")\n",
    "\n",
    "pie_nonsurvivors_pclass = go.Pie(  \n",
    "   labels = df_nonsurvivors_pclass['Pclass'],\n",
    "   values = df_nonsurvivors_pclass['count'],\n",
    "   domain=dict(x=[0.5, 1.0]), \n",
    "   name='non-Survivors',\n",
    "   hole = 0.5,\n",
    "   marker = dict(colors=['#EF553B', '#00CC96', '#636EFA'], \n",
    "                 line=dict(color='#000000', width=2))\n",
    ")\n",
    "\n",
    "data = [pie_survivors_pclass, pie_nonsurvivors_pclass]\n",
    "\n",
    "# Plot's Layout (background color, title, annotations, etc.)\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    title='\"Pclass\" percentage from Survivors vs non-Survivors',\n",
    "    annotations=[dict(text='Survivors', x=0.18, y=0.5, \n",
    "                      font_size=15, showarrow=False),\n",
    "                 dict(text='Non-Survivors', x=0.85, y=0.5, \n",
    "                      font_size=15, showarrow=False)]\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929f075-17a0-4f7c-b1a5-6106caa896ba",
   "metadata": {},
   "source": [
    "#### \"Fare\" value of survivors vs \"Fare\" value of non-survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af23a6-6392-49e2-95e0-8bad5d382f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out the differences between Fare distribution \n",
    "# for survivors and non-survivors\n",
    "fare_survivors_box = go.Box(  \n",
    "   x=df_survivors['Fare'],\n",
    "   name='Survivors',\n",
    "   marker=dict(color='navy')\n",
    ")\n",
    "\n",
    "fare_nonsurvivors_box = go.Box(  \n",
    "   x=df_nonsurvivors['Fare'],\n",
    "   name='Non-Survivors',\n",
    "   marker=dict(color='steelblue')\n",
    ")\n",
    "  \n",
    "data = [fare_nonsurvivors_box, fare_survivors_box]\n",
    "\n",
    "# Plot's Layout (background color, title, etc.)\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    title='\"Fare\" value of survivors vs \"Fare\" value of non-survivors',\n",
    "    barmode='stack',\n",
    "    xaxis=dict(\n",
    "        title='Fare distribution'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5cb45-095f-40c9-87f5-3db393e624fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third distribution for the hypothesis test - Fares of survivors\n",
    "dist_c = df_survivors['Fare'].dropna()\n",
    "\n",
    "# Fourth distribution for the hypothesis test - Fares of non-survivors\n",
    "dist_d = df_nonsurvivors['Fare'].dropna()\n",
    "\n",
    "# Z-test: Checking if the distribution means \n",
    "# (fares of survivors vs fares of non-survivors) are statistically different\n",
    "t_stat_3, p_value_3 = ztest(dist_c, dist_d)\n",
    "print(\"----- Z Test Results -----\")\n",
    "print(\"T stat. = \" + str(t_stat_3))\n",
    "print(\"P value = \" + str(p_value_3)) # P-value is less than 0.05\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# T-test: Checking if the distribution means \n",
    "# (fares of survivors vs fares of non-survivors) are statistically different\n",
    "t_stat_4, p_value_4 = stats.ttest_ind(dist_c, dist_d)\n",
    "print(\"----- T Test Results -----\")\n",
    "print(\"T stat. = \" + str(t_stat_4))\n",
    "print(\"P value = \" + str(p_value_4)) # P-value is less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c18b2-a9ed-4d5e-8af8-c734fa6e8d90",
   "metadata": {},
   "source": [
    "#### PPS (Predictive Power Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41682a2e-b492-4ee9-8b2a-87838c2245b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pps.matrix(df)[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "matrix_df = matrix_df.apply(lambda x: round(x, 2)) # Rounding matrix_df's values to 0,XX\n",
    "\n",
    "sns.heatmap(matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.75, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4255f-376f-45f0-a158-b370ec66a8c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7313b-30ab-4170-ae79-653d630b6424",
   "metadata": {},
   "source": [
    "## Section 2 - Supervised Learning: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39fa2e-ceae-43d4-9818-95c68807bf10",
   "metadata": {},
   "source": [
    "Let's dive into the modeling part.  \n",
    "Import the libraries we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9bd38-fcff-4c0b-aa2e-d892eb30b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from xgboost import XGBClassifier, plot_importance as plot_importance_xgb\n",
    "from lightgbm import LGBMClassifier, plot_importance as plot_importance_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd230f-7007-4119-9234-fd34b23657a3",
   "metadata": {},
   "source": [
    "#### Feature Engineering  \n",
    "Create new features based on the original features of our dataset.  \n",
    "https://www.kaggle.com/gunesevitan/titanic-advanced-feature-engineering-tutorial   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ae598-8a7b-45d7-ad1e-2326a31989b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a categorical variable for Ages\n",
    "df['AgeCat'] = ''\n",
    "df['AgeCat'].loc[(df['Age'] < 18)] = 'young'\n",
    "df['AgeCat'].loc[(df['Age'] >= 18) & (df['Age'] < 56)] = 'mature'\n",
    "df['AgeCat'].loc[(df['Age'] >= 56)] = 'senior'\n",
    "\n",
    "# Creating a categorical variable for Family Sizes\n",
    "df['FamilySize'] = ''\n",
    "df['FamilySize'].loc[(df['SibSp'] <= 2)] = 'small'\n",
    "df['FamilySize'].loc[(df['SibSp'] > 2) & (df['SibSp'] <= 5 )] = 'medium'\n",
    "df['FamilySize'].loc[(df['SibSp'] > 5)] = 'large'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is alone\n",
    "df['IsAlone'] = ''\n",
    "df['IsAlone'].loc[((df['SibSp'] + df['Parch']) > 0)] = 'no'\n",
    "df['IsAlone'].loc[((df['SibSp'] + df['Parch']) == 0)] = 'yes'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is a Young/Mature/Senior male \n",
    "# or a Young/Mature/Senior female\n",
    "df['GenderCat'] = ''\n",
    "df['GenderCat'].loc[(df['Gender'] == 'male') & (df['Age'] <= 21)] = 'youngmale'\n",
    "df['GenderCat'].loc[(df['Gender'] == 'male') & ((df['Age'] > 21) & (df['Age']) < 50)] = 'maturemale'\n",
    "df['GenderCat'].loc[(df['Gender'] == 'male') & (df['Age'] > 50)] = 'seniormale'\n",
    "df['GenderCat'].loc[(df['Gender'] == 'female') & (df['Age'] <= 21)] = 'youngfemale'\n",
    "df['GenderCat'].loc[(df['Gender'] == 'female') & ((df['Age'] > 21) & (df['Age']) < 50)] = 'maturefemale'\n",
    "df['GenderCat'].loc[(df['Gender'] == 'female') & (df['Age'] > 50)] = 'seniorfemale'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c396314-8423-4605-90d3-1ebae99946fd",
   "metadata": {},
   "source": [
    "Creating a categorical variable for the passenger's title  \n",
    "Title is created by extracting the prefix before \"Name\" feature  \n",
    "This title needs to be a feature because all female titles are grouped with each other  \n",
    "Also, creating a column to tell if the passenger is married or not  \n",
    "\"Is_Married\" is a binary feature based on the Mrs title. Mrs title has the highest survival rate among other female titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71399d16-265e-4917-bcb5-10ea8199a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check : Name Feature\n",
    "df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85852c9-242e-484c-8a15-d5081adbfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check : Ticket Frequency\n",
    "df1 = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "#df1 = df.groupby('Ticket')['Ticket']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e07f5b-003d-49cc-9298-65b6fe5055d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df['Is_Married'] = 0\n",
    "df['Is_Married'].loc[df['Title'] == 'Mrs'] = 1\n",
    "df['Title'] = df['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df['Title'] = df['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "# Creating \"Ticket Frequency\" Feature\n",
    "# There are too many unique Ticket values to analyze, so grouping them up by their frequencies makes things easier\n",
    "df['Ticket_Frequency'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c145e6-4726-462d-9425-526a630214ed",
   "metadata": {},
   "source": [
    "After creating new features, we can drop useless columns that we won't use in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9010d05-3178-4489-bc10-67c0d7229ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(df):\n",
    "    # Splitting the target\n",
    "    target = df['Survived']\n",
    "\n",
    "    # Dropping unused columns from the feature set\n",
    "    df.drop(['PassengerId', 'Survived', 'Ticket', 'Name', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "    # Splitting categorical and numerical column dataframes\n",
    "    categorical_df = df.select_dtypes(include=['object'])\n",
    "    numeric_df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "    # And then, storing the names of categorical and numerical columns.\n",
    "    categorical_columns = list(categorical_df.columns)\n",
    "    numeric_columns = list(numeric_df.columns)\n",
    "    \n",
    "    print(\"Categorical columns:\\n\", categorical_columns)\n",
    "    print(\"\\nNumeric columns:\\n\", numeric_columns)\n",
    "\n",
    "    return target, categorical_columns, numeric_columns\n",
    "\n",
    "target, categorical_columns, numeric_columns = get_feature_names(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e4555-4d7f-4789-ba7b-c133e0c5e716",
   "metadata": {},
   "source": [
    "#### Model training & Evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3c528-2e85-4e95-9944-4458a7d83f6a",
   "metadata": {},
   "source": [
    "After all the preprocessing, we are now ready to build and evaluate different Machine Learning models.  \n",
    "First, let's create a function responsible for evaluating our classifiers on a test set we will create later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90932c9e-1041-4cc4-a15a-00b6364cf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function responsible for checking our model's performance on the test data\n",
    "def testSetResultsClassifier(best_model_pipeline, x_test, y_test):\n",
    "    results = []\n",
    "    \n",
    "    predictions = best_model_pipeline.best_estimator_.predict(x_test)\n",
    "\n",
    "    # Metrics applied on Probabilistic models and GLMs (predicted_proba for \n",
    "    # probabilistic ones, decision_function for GLMs)\n",
    "    predicted_probas_class1 = best_model_pipeline.best_estimator_.predict_proba(x_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, predicted_probas_class1)\n",
    "    avg_precision = average_precision_score(y_test, predicted_probas_class1)\n",
    "    \n",
    "    # Universal metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    results.append(accuracy)\n",
    "    results.append(precision)\n",
    "    results.append(recall)\n",
    "    results.append(f1)\n",
    "    results.append(avg_precision)\n",
    "    results.append(roc_auc)\n",
    "    \n",
    "    print(\"\\n\\n#------- Test set results (Best Classifier) -------#\\n\")\n",
    "    print(\"Accuracy:\", round(results[0], 3))\n",
    "    print(\"Precision:\", round(results[1], 3))\n",
    "    print(\"Recall:\", round(results[2], 3))\n",
    "    print(\"F1-Score:\", round(results[3], 3))\n",
    "    print(\"Average Precision (Precision/Recall AUC):\", round(results[4], 3))\n",
    "    print(\"ROC_AUC:\", round(results[5], 3))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c364a00-8b21-4be5-95c3-2e023797d7d0",
   "metadata": {},
   "source": [
    "#### Pipeline Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50738f34-ccfc-47eb-b8ed-4cb4d36f9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Now, we are going to create our Pipeline, fitting several different data preprocessing and modeling\n",
    "# techniques inside a RandomSearchCV, to check which group of techniques has better performance.\n",
    "\n",
    "# Building a Pipeline inside RandomSearchCV, responsible for finding the best model and it's parameters\n",
    "def defineBestModelPipeline(df, target, numeric_columns, categorical_columns):\n",
    "    \n",
    "    # Splitting original data into Train and Test BEFORE applying transformations\n",
    "    # Later in RandomSearchCV, x_train will be splitted into train/val sets\n",
    "    # The transformations are going to be fitted specifically on the train set,\n",
    "    # and then applied to both train/test sets. This way, information leakage is avoided!\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.10, random_state=42)\n",
    "    \n",
    "    \n",
    "    # 1st -> #### ----------- Numeric Transformers ----------- ####\n",
    "    \n",
    "    # Here, we are creating different several different data transformation pipelines \n",
    "    # to be applied in our numeric features\n",
    "    numeric_transformer_1 = Pipeline(steps=[('imp', IterativeImputer(max_iter=30, random_state=42)),\n",
    "                                            ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    numeric_transformer_2 = Pipeline(steps=[('imp', SimpleImputer(strategy='mean')), # or strategy='median'\n",
    "                                            ('scaler', StandardScaler())])\n",
    "\n",
    "    \n",
    "    # 2nd -> #### ----------- Categorical Transformers ----------- ####\n",
    "    \n",
    "    # We are going to encode categorical features using LeaveOneOutEncoder and TargetEncoder.\n",
    "    # Note: TargetEncoder uses the mean target values (probabilities for classification and \n",
    "    # continuous values for regression) of each category inside a column to encode them.\n",
    "    \n",
    "    # LeaveOneOutEncoder is an alternative to TargetEncoder. It implements an improvement on TargetEncoder's\n",
    "    # \"overfitting behaviour\", by leaving 1 of the observations out of the mean calculation for a specific category.\n",
    "    # Read about it here: https://towardsdatascience.com/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809\n",
    "    # Documentation: https://contrib.scikit-learn.org/category_encoders/leaveoneout.html\n",
    "    \n",
    "    categorical_transformer_1 = Pipeline(steps=[('frequent', SimpleImputer(strategy='most_frequent')),\n",
    "                                                ('leaveoneout', LeaveOneOutEncoder(sigma=0.1))])\n",
    "    \n",
    "    categorical_transformer_2 = Pipeline(steps=[('frequent', SimpleImputer(strategy='most_frequent')),\n",
    "                                                ('targetencoder', TargetEncoder(min_samples_leaf=3, smoothing=2))])\n",
    "    \n",
    "    \n",
    "    # 3rd -> #### ----------- Combining both numerical and categorical data pipelines ----------- ####\n",
    "    \n",
    "    # Here, we are creating different ColumnTransformers, each one with a different numerical/categotical transformation\n",
    "    data_transformations_1 = ColumnTransformer(transformers=[('num', numeric_transformer_1, numeric_columns),\n",
    "                                                             ('cat', categorical_transformer_1, categorical_columns)])\n",
    "    \n",
    "    data_transformations_2 = ColumnTransformer(transformers=[('num', numeric_transformer_1, numeric_columns),\n",
    "                                                             ('cat', categorical_transformer_2, categorical_columns)])\n",
    "    \n",
    "    data_transformations_3 = ColumnTransformer(transformers=[('num', numeric_transformer_2, numeric_columns),\n",
    "                                                             ('cat', categorical_transformer_1, categorical_columns)])\n",
    "    \n",
    "    data_transformations_4 = ColumnTransformer(transformers=[('num', numeric_transformer_2, numeric_columns),\n",
    "                                                             ('cat', categorical_transformer_2, categorical_columns)])\n",
    "    \n",
    "    \n",
    "    # 4th -> #### ----------- Testing different data transformation steps and models inside RandomSearchCV ----------- ####\n",
    "    \n",
    "    # Finally, we are going to apply these different data transformations to RandomSearchCV,\n",
    "    # trying to find the best imputing strategy, the best feature transformation strategy and the best model with it's respective parameters.\n",
    "    # Below, we just need to initialize a Pipeline object with any transformations we want, on each of the steps.\n",
    "\n",
    "    pipe = Pipeline(steps=[('data_transformations', data_transformations_1), # Initializing data transformation step by choosing any of the above\n",
    "                           ('clf', SVC())]) # Initializing modeling step with any model object\n",
    "                           #memory='cache_folder') -> Used to optimize memory when needed\n",
    "    \n",
    "    # Now, we define the hyperparameter grid that will be used by RandomSearchCV. It will randomly chose options \n",
    "    # for each step inside the dictionaries ('data transformations', 'feature_selection', 'clf' and clf's parameters). \n",
    "    # Then, for each chosen option, it will apply the transformations, train the chosen model and evaluate \n",
    "    # it in the validation fold of the cross validator we define. In the end of it's iterations, RandomSearchCV will return some metrics, \n",
    "    # such as the best pipeline, model results for all iterations and more.\n",
    "    \n",
    "    params_grid = [   \n",
    "                    {'data_transformations': [data_transformations_1, data_transformations_2,\n",
    "                                              data_transformations_3, data_transformations_4],\n",
    "                     'clf': [RandomForestClassifier()],\n",
    "                     'clf__n_estimators': [int(x) for x in np.linspace(5, 30, num=15)],\n",
    "                     'clf__max_features': [None, \"sqrt\", \"log2\"],\n",
    "                     'clf__max_depth': [int(x) for x in np.linspace(3, 10, num=5)],\n",
    "                     'clf__random_state': [int(x) for x in np.linspace(1, 49, num=30)]},\n",
    "                        \n",
    "                    {'data_transformations': [data_transformations_1, data_transformations_2,\n",
    "                                              data_transformations_3, data_transformations_4],\n",
    "                     'clf': [LGBMClassifier()],\n",
    "                     'clf__n_estimators': [int(x) for x in np.linspace(3, 20, num=10)],\n",
    "                     'clf__max_depth': [int(x) for x in np.linspace(2, 8, num=6)],\n",
    "                     'clf__learning_rate': np.linspace(0.1, 0.7)},\n",
    "        \n",
    "                    {'data_transformations': [data_transformations_1, data_transformations_2,\n",
    "                                              data_transformations_3, data_transformations_4],\n",
    "                     'clf': [XGBClassifier()],\n",
    "                     'clf__n_estimators': [int(x) for x in np.linspace(3, 15, num=10)],\n",
    "                     'clf__eta': np.linspace(0.1, 0.9),\n",
    "                     'clf__max_depth': [int(x) for x in np.linspace(2, 7, num=5)],\n",
    "                     'clf__gamma': np.linspace(0.1, 1),\n",
    "                     'clf__lambda': np.linspace(0.1, 1)},\n",
    "                ]\n",
    "    \n",
    "    # Now, we fit a RandomSearchCV to search over the grid of parameters defined above\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'average_precision', 'roc_auc']\n",
    "    \n",
    "    # Creating our cross validator object with StratifiedShuffleSplit (5 folds).\n",
    "    # Stratification assures that we split the data such that the proportions\n",
    "    # between classes are the same in each fold as they are in the whole dataset\n",
    "    cross_validator = StratifiedShuffleSplit(n_splits=5, train_size=0.8, test_size=0.2, random_state=7)\n",
    "    \n",
    "    # Creating the randomized search cv object and fitting it\n",
    "    best_model_pipeline = RandomizedSearchCV(estimator=pipe, param_distributions=params_grid, \n",
    "                                             n_iter=50, scoring=metrics, refit='accuracy', \n",
    "                                             n_jobs=-1, cv=cross_validator, random_state=21,\n",
    "                                             error_score='raise', return_train_score=False)\n",
    "\n",
    "    best_model_pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # At last, we check the final results\n",
    "    print(\"\\n\\n#--------- Best Data Pipeline found in RandomSearchCV ---------#\\n\\n\", best_model_pipeline.best_estimator_[0])\n",
    "    print(\"\\n\\n#--------- Best Classifier found in RandomSearchCV ---------#\\n\\n\", best_model_pipeline.best_estimator_[1])\n",
    "    print(\"\\n\\n#--------- Best Estimator's average Accuracy Score on CV (validation set) ---------#\\n\\n\", best_model_pipeline.best_score_)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, best_model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df47e31-db41-4dfb-b969-3fed4675f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function above, returing train/test data and best model's pipeline\n",
    "x_train, x_test, y_train, y_test, best_model_pipeline = defineBestModelPipeline(df, target, numeric_columns, categorical_columns)\n",
    "\n",
    "# Checking best model's performance on test data\n",
    "test_set_results = testSetResultsClassifier(best_model_pipeline, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e224-ad1c-4d27-b847-70c6516bd66c",
   "metadata": {},
   "source": [
    "Visual representation of the best pipeline found by RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cebf9-d769-46ad-ac1b-16d9a9ea2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "# Set config to 'diagram' so we can visualize pipelines/composite estimators\n",
    "set_config(display='diagram')\n",
    "\n",
    "# Visualization of the best estimator found by RandomSearchCV\n",
    "best_model_pipeline.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e8190-1127-4eeb-8367-ddc78eef7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pipeline.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625be7e-cee2-4c6e-b392-202d5a6de258",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pipeline.best_estimator_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b4d81-f6d0-4ccb-bbd4-ea5e9d457cf0",
   "metadata": {},
   "source": [
    "#### Precision-Recall and ROC Curves  \n",
    "\n",
    "Let's take a look at the Precision/Recall and ROC Curves of the best model in our separate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e8d70-38ab-44cd-b819-3e252b91042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the test data\n",
    "x_test = best_model_pipeline.best_estimator_[0].transform(x_test)\n",
    "\n",
    "# Calculating precision/recall threshold values for Probabilistic models\n",
    "precision, recall, thresholds_prc = precision_recall_curve(y_test, best_model_pipeline.best_estimator_[1].predict_proba(x_test)[:, 1])\n",
    "closest_to_025_prc = np.argmin(np.abs(thresholds_prc - 0.25))    # Getting information about the points in the graph that \n",
    "closest_to_default_prc = np.argmin(np.abs(thresholds_prc - 0.5)) # are closer to the default threshold for predict_proba (0.5),\n",
    "closest_to_075_prc = np.argmin(np.abs(thresholds_prc - 0.75))    # threshold 0.25 and threshold 0.75.\n",
    "\n",
    "# Plotting the curve\n",
    "plt.plot(precision, recall, label=\"Results, Pecision Recall Curve\")\n",
    "plt.plot(precision[closest_to_025_prc], recall[closest_to_025_prc], 'v', c='k', # Plotting the marker for threshold 0.25\n",
    "         markersize=10, label=\"Threshold 0.25\", fillstyle=\"none\", mew=2)       \n",
    "plt.plot(precision[closest_to_default_prc], recall[closest_to_default_prc], 's', c='k', # Plotting the marker for threshold 0.5 (default)\n",
    "         markersize=10, label=\"Default threshold (0.5)\", fillstyle=\"none\", mew=2)        \n",
    "plt.plot(precision[closest_to_075_prc], recall[closest_to_075_prc], '^', c='k', # Plotting the marker for threshold 0.75 \n",
    "         markersize=10, label=\"Threshold 0.75\", fillstyle=\"none\", mew=2)\n",
    "plt.title(\"Precision-Recall Curve for the best model found\")\n",
    "plt.xlabel(\"Precision: TP / (TP + FP)\")\n",
    "plt.ylabel(\"Recall: TP / (TP + FN)\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd1bb7-2f9a-4387-b1a7-f8c27328893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing all results and metrics, from all models, obtained by the RandomSearchCV steps\n",
    "df_results = pd.DataFrame(best_model_pipeline.cv_results_)\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "display(df_results.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8dc9d-7d79-4980-8617-645b6df93048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing all results and metrics obtained only by the best classifier, considering Accuracy score\n",
    "display(df_results[df_results['rank_test_accuracy'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019c443-8ae6-47d4-a56a-464845e84a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing all results and metrics obtained only by the best classifier, considering ROC_AUC score\n",
    "display(df_results[df_results['rank_test_roc_auc'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0044b6-a055-42ab-a5d4-7bb0996e3787",
   "metadata": {},
   "source": [
    "#### Plotting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b5592-3632-47f0-86f2-16fcf4cb763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_in_order = numeric_columns + categorical_columns\n",
    "print(feature_names_in_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd1574-01d0-41e4-a38e-39892b776758",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Plotting Feature Importances for Random Forests & XGBoost #####\n",
    "feat_importances = pd.Series(best_model_pipeline.best_estimator_.named_steps['clf'].feature_importances_, \n",
    "                             index=feature_names_in_order)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acfa824-babe-4867-be77-168bbfd66303",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57b07f-7efe-4c08-8144-ee74e3d261e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data and displaying some rows\n",
    "df_test = pd.read_csv(\"data/input/test.csv\")\n",
    "\n",
    "# Creating a categorical variable for Ages\n",
    "df_test['AgeCat'] = ''\n",
    "df_test['AgeCat'].loc[(df_test['Age'] < 18)] = 'young'\n",
    "df_test['AgeCat'].loc[(df_test['Age'] >= 18) & (df_test['Age'] < 56)] = 'mature'\n",
    "df_test['AgeCat'].loc[(df_test['Age'] >= 56)] = 'senior'\n",
    "\n",
    "# Creating a categorical variable for Family Sizes\n",
    "df_test['FamilySize'] = ''\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] <= 2)] = 'small'\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] > 2) & (df_test['SibSp'] <= 5 )] = 'medium'\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] > 5)] = 'large'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is alone\n",
    "df_test['IsAlone'] = ''\n",
    "df_test['IsAlone'].loc[((df_test['SibSp'] + df_test['Parch']) > 0)] = 'no'\n",
    "df_test['IsAlone'].loc[((df_test['SibSp'] + df_test['Parch']) == 0)] = 'yes'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is a Young/Mature/Senior male or a Young/Mature/Senior female\n",
    "df_test['GenderCat'] = ''\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & (df_test['Age'] <= 21)] = 'youngmale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & ((df_test['Age'] > 21) & (df_test['Age']) < 50)] = 'maturemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & (df_test['Age'] > 50)] = 'seniormale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & (df_test['Age'] <= 21)] = 'youngfemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & ((df_test['Age'] > 21) & (df_test['Age']) < 50)] = 'maturefemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & (df_test['Age'] > 50)] = 'seniorfemale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca5d3c-61fb-4e27-acdf-99040612ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data and displaying some rows\n",
    "df_test = pd.read_csv(\"data/input/test.csv\")\n",
    "\n",
    "# Creating a categorical variable for Ages\n",
    "df_test['AgeCat'] = ''\n",
    "df_test['AgeCat'].loc[(df_test['Age'] < 18)] = 'young'\n",
    "df_test['AgeCat'].loc[(df_test['Age'] >= 18) & (df_test['Age'] < 56)] = 'mature'\n",
    "df_test['AgeCat'].loc[(df_test['Age'] >= 56)] = 'senior'\n",
    "\n",
    "# Creating a categorical variable for Family Sizes\n",
    "df_test['FamilySize'] = ''\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] <= 2)] = 'small'\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] > 2) & (df_test['SibSp'] <= 5 )] = 'medium'\n",
    "df_test['FamilySize'].loc[(df_test['SibSp'] > 5)] = 'large'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is alone\n",
    "df_test['IsAlone'] = ''\n",
    "df_test['IsAlone'].loc[((df_test['SibSp'] + df_test['Parch']) > 0)] = 'no'\n",
    "df_test['IsAlone'].loc[((df_test['SibSp'] + df_test['Parch']) == 0)] = 'yes'\n",
    "\n",
    "# Creating a categorical variable to tell if the passenger is a Young/Mature/Senior male or a Young/Mature/Senior female\n",
    "df_test['GenderCat'] = ''\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & (df_test['Age'] <= 21)] = 'youngmale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & ((df_test['Age'] > 21) & (df_test['Age']) < 50)] = 'maturemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'male') & (df_test['Age'] > 50)] = 'seniormale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & (df_test['Age'] <= 21)] = 'youngfemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & ((df_test['Age'] > 21) & (df_test['Age']) < 50)] = 'maturefemale'\n",
    "df_test['GenderCat'].loc[(df_test['Gender'] == 'female') & (df_test['Age'] > 50)] = 'seniorfemale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0037da4-7dc1-49fb-81fe-df7dff22d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a categorical variable for the passenger's title\n",
    "# Title is created by extracting the prefix before \"Name\" feature\n",
    "# This title needs to be a feature because all female titles are grouped with each other\n",
    "# Also, creating a column to tell if the passenger is married or not\n",
    "# \"Is_Married\" is a binary feature based on the Mrs title. Mrs title has the highest survival rate among other female titles\n",
    "df_test['Title'] = df_test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_test['Is_Married'] = 0\n",
    "df_test['Is_Married'].loc[df_test['Title'] == 'Mrs'] = 1\n",
    "df_test['Title'] = df_test['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_test['Title'] = df_test['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "# Creating \"Ticket Frequency\" Feature\n",
    "# There are too many unique Ticket values to analyze, so grouping them up by their frequencies makes things easier\n",
    "df_test['Ticket_Frequency'] = df_test.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "df_test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e670fd-cb87-45be-8cac-08d114de4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying best_model_pipeline\n",
    "# Step 1 -> Transforming data the same way we did in the training set;\n",
    "# Step 2 -> making predictions using the best model obtained by RandomSearchCV.\n",
    "test_predictions = best_model_pipeline.best_estimator_.predict(df_test)\n",
    "\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcdb4c4-c5bf-46fe-be2e-93f6a8707df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions file that is going to be submitted to the competition\n",
    "df_submission = pd.read_csv(\"data/input/test.csv\")\n",
    "\n",
    "# Adding a column with predicted values\n",
    "df_submission['Survived'] = test_predictions\n",
    "\n",
    "# Selecting only needed columns\n",
    "df_submission.drop(df_submission.columns.difference(['PassengerId', 'Survived']), axis=1, inplace=True)\n",
    "\n",
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e803d-589a-490e-8882-9ece7060435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the number of rows is OK (the file is expected to have 418 rows)\n",
    "df_submission.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c4244-ca91-4655-8879-a291eccdcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing submitions to CSV file\n",
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f495735-5f92-46e9-bc07-8453bafe576c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
